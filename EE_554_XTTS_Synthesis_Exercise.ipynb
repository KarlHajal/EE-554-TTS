{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3lGaXmqvKhvy"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarlHajal/EE-554-TTS/blob/main/EE_554_XTTS_Synthesis_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EE-554 XTTS Synthesis Exercise\n",
        "\n",
        "## Introduction\n",
        "The goal of this exercise is to get familiar with modern text-to-speech (TTS) technology and explore the strengths and limitations of a popular open-source TTS model. We will use the Coqui.ai TTS library, which provides pre-trained neural models that are easy to download and use with just a few lines of code. In this exercise, we will focus on Coqui's XTTS model. This is a multi-lingual TTS model trained on 16 languages. It also supports zero-shot voice cloning, meaning that the model can copy a person’s voice after listening to a short sample, even if it has never seen that voice before during training.\n",
        "\n",
        "To ensure the model inference is fast, **you can use a GPU runtime**. In the toolbar above, go to Runtime > Change runtime type, select T4 GPU, and Save.  "
      ],
      "metadata": {
        "id": "vecn_J6ZE02_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Install Requirements"
      ],
      "metadata": {
        "id": "3lGaXmqvKhvy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-nvp_QiEiOr"
      },
      "outputs": [],
      "source": [
        "!pip install coqui-tts\n",
        "!pip install ipywebrtc\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "from ipywebrtc import AudioRecorder, CameraStream\n",
        "from IPython.display import Audio, display, Markdown\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "import torch\n",
        "from TTS.api import TTS\n",
        "\n",
        "# Get device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Download audio files"
      ],
      "metadata": {
        "id": "jSEma1B-KrXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KarlHajal/EE-554-TTS/\n",
        "!mv /content/EE-554-TTS/voice_examples /content/"
      ],
      "metadata": {
        "id": "xGDidW5qK-Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Synthesis and Voice Cloning\n",
        "\n",
        "Below, we will first test the XTTS model using a natural average voice in different languages. Next, we will try cloning different voices to see how well the model can imitate them. Finally, we will record our own voice samples and test how we can influence the model's outputs."
      ],
      "metadata": {
        "id": "y6ZkrgbGLA5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the XTTS model\n",
        "# When prompted, write 'y' in the text box and press enter to agree to the terms and conditions\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)"
      ],
      "metadata": {
        "id": "ryJnnFDjIzmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **I - Multi-lingual Synthesis**\n",
        "First, we will synthesize sentences in different languages using a US English female voice as the reference."
      ],
      "metadata": {
        "id": "q-bZC8DPXB4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run XTTS\n",
        "# XTTS is a multi-lingual and voice cloning text-to-speech model.\n",
        "# The tts_to_file method below takes as inputs the text to transcribe, the language, and the reference voice clip.\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/libri121.wav\", language=\"en\", file_path=\"english_output.wav\")\n",
        "display(Markdown(\"English Output:\"))\n",
        "display(Audio(\"/content/english_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"J'ai oublié mon parapluie et bien sûr, il a commencé à pleuvoir.\", language=\"fr\", speaker_wav=\"voice_examples/libri121.wav\", file_path=\"french_output.wav\")\n",
        "display(Markdown(\"French Output:\"))\n",
        "display(Audio(\"/content/french_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"Ich habe meinen Regenschirm vergessen und natürlich hat es angefangen zu regnen.\", language=\"de\", speaker_wav=\"voice_examples/libri121.wav\", file_path=\"german_output.wav\")\n",
        "display(Markdown(\"German Output:\"))\n",
        "display(Audio(\"/content/german_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"Ho dimenticato l'ombrello e, naturalmente, ha cominciato a piovere.\", language=\"it\", speaker_wav=\"voice_examples/libri121.wav\", file_path=\"italian_output.wav\")\n",
        "display(Markdown(\"Italian Output:\"))\n",
        "display(Audio(\"/content/italian_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"Olvidé mi paraguas y, por supuesto, empezó a llover.\", language=\"es\", speaker_wav=\"voice_examples/libri121.wav\", file_path=\"spanish_output.wav\")\n",
        "display(Markdown(\"Spanish Output:\"))\n",
        "display(Audio(\"/content/spanish_output.wav\", autoplay=False))"
      ],
      "metadata": {
        "id": "CZCfQfeHFwS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Analysis Questions**\n",
        "1 - What did you think about the quality of the model's outputs?\n",
        "- What aspects of the output were good?\n",
        "- What issues or problems did you notice?\n",
        "\n",
        "2 - How should we evaluate the model's performance?\n",
        "- What important dimensions or qualities should we focus on?\n",
        "\n",
        "3 - What methods can we use to measure these dimensions?\n",
        "- What metrics or evaluation approaches can be used?"
      ],
      "metadata": {
        "id": "zUXSavt0aKa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **II - Voice Cloning**\n",
        "Next, we will clone a variety of interesting voices and observe the results. Before each synthesized output, you can also play the reference voice sample provided to the model for imitation."
      ],
      "metadata": {
        "id": "Ca-HXSk6aO33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/morgan.mp3\", language=\"en\", file_path=\"morgan_output.wav\")\n",
        "display(Markdown(\"###**Morgan:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/morgan.mp3\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/morgan_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/david.mp3\", language=\"en\", file_path=\"david_output.wav\")\n",
        "display(Markdown(\"###**David:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/david.mp3\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/david_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/thorsten_angry.wav\", language=\"en\", file_path=\"thorsten_angry_output.wav\")\n",
        "display(Markdown(\"###**Thorsten Angry:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/thorsten_angry.wav\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/thorsten_angry_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/thorsten_whisper.wav\", language=\"en\", file_path=\"thorsten_whisper_output.wav\")\n",
        "display(Markdown(\"###**Thorsten Whisper:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/thorsten_whisper.wav\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/thorsten_whisper_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/michael.mp3\", language=\"en\", file_path=\"michael_output.wav\")\n",
        "display(Markdown(\"###**Michael:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/michael.mp3\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/michael_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/arnold.mp3\", language=\"en\", file_path=\"arnold_output.wav\")\n",
        "display(Markdown(\"###**Arnold:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/arnold.mp3\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/arnold_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/sean.mp3\", language=\"en\", file_path=\"sean_output.wav\")\n",
        "display(Markdown(\"###**Sean:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/sean.mp3\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/sean_output.wav\", autoplay=False))\n",
        "\n",
        "tts.tts_to_file(text=\"I forgot my umbrella, and of course, it started raining.\", speaker_wav=\"voice_examples/marvin.mp3\", language=\"en\", file_path=\"marvin_output.wav\")\n",
        "display(Markdown(\"###**Marvin:**\"))\n",
        "display(Markdown(\"Reference:\"))\n",
        "display(Audio(\"voice_examples/marvin.mp3\", autoplay=False))\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/marvin_output.wav\", autoplay=False))\n"
      ],
      "metadata": {
        "id": "mnW3Y7V5aMaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Analysis Questions**\n",
        "1 - Did the quality of the outputs vary across different cases?\n",
        "\n",
        "2 - What aspects of each voice did the model clone well?\n",
        "- What details were missing or inaccurate?\n",
        "\n",
        "3 - How should we evaluate the model’s ability to handle multiple speakers and voice cloning?\n",
        "- What key features or dimensions should we focus on?\n",
        "\n",
        "4 - What metrics and evaluation methods can help assess these features?\n"
      ],
      "metadata": {
        "id": "N98C1M8PbQi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Record and Clone your own voice\n",
        "\n",
        "In this step, you will record your voice using the tool below, and use the recorded sample as a reference for the TTS model to clone. In each case, try to record a minimum of 5 seconds.\n",
        "\n",
        "1. **Quiet Environment**: Start by recording yourself in a quiet environment, reading any sentence of your choice using a neutral tone.\n",
        "\n",
        "2. **Noisy Environment**: Record the same sentence again, this time in a noisy environment. (e.g. introduce background noise such as music or ambient sounds from your phone).\n",
        "\n",
        "3. **Voice Modulation**: Record the sentence in a quiet environment again, but this time modulate your voice in various ways (e.g., change your pitch, speed, or tone) to observe how this affects the synthesized outputs. You can try to change your voice several times in the same recording to test what the model will pick up one.\n",
        "\n",
        "Make sure to grant the browser access to your microphone when prompted. If the recording button doesn't work the first time you grant it permission, try to rerun the cell. After that you should be able to start recording by pressing the record button the first time (the dot will turn red), speaking into the mic, and then pressing the record button a second time to save the recording."
      ],
      "metadata": {
        "id": "Rnpak2MXZy3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "camera = CameraStream(constraints={'audio': True,'video':False})\n",
        "recorder = AudioRecorder(stream=camera)\n",
        "recorder"
      ],
      "metadata": {
        "id": "Pk1O3_VgP75q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('my_recording.webm', 'wb') as f:\n",
        "    f.write(recorder.audio.value)\n",
        "!ffmpeg -i my_recording.webm -ac 1 -f wav my_recording.wav -y -hide_banner -loglevel panic\n",
        "tts.tts_to_file(text=\"Peter Piper picked a peck of pickled peppers. A peck of pickled peppers Peter Piper picked.\", speaker_wav=\"my_recording.wav\", language=\"en\", file_path=\"my_voice_output.wav\")\n",
        "display(Markdown(\"Output:\"))\n",
        "display(Audio(\"/content/my_voice_output.wav\", autoplay=False))"
      ],
      "metadata": {
        "id": "jDtdEzqiP9x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Analysis Questions:**\n",
        "1 - Did the model clone your voice accurately?\n",
        "- What features did it replicate well?\n",
        "- What was missing or inaccurate?\n",
        "\n",
        "2 - Did adding noise or music to the reference recording affect the output?\n",
        "\n",
        "3 - How did changing or modulating your voice affect the results?\n",
        "\n",
        "4 - What interesting observations did you make?\n",
        "\n",
        "5 - Did you notice any strange outputs?\n",
        "- Did the model produce unexpected or unrealistic results (hallucinations)?"
      ],
      "metadata": {
        "id": "ePJN3auCS-rp"
      }
    }
  ]
}